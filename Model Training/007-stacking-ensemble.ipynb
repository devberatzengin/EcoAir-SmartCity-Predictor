{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32006000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from datetime import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee1c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/beratzengin/Desktop/Github/EcoAir SmartCity Predictor/Feature Engineering\"\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(PATH, 'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(PATH, 'test.csv'))\n",
    "\n",
    "target = 'PM10'\n",
    "features = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "if target in features:\n",
    "    features.remove(target)\n",
    "\n",
    "X_train = train_df[features].fillna(0)\n",
    "y_train = train_df[target].fillna(train_df[target].mean())\n",
    "\n",
    "X_test = test_df[features].fillna(0)\n",
    "y_test = test_df[target].fillna(test_df[target].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff693d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Stacking Ensemble\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3105\n",
      "[LightGBM] [Info] Number of data points in the train set: 166766, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 39.047001\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3106\n",
      "[LightGBM] [Info] Number of data points in the train set: 133413, number of used features: 16\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3102\n",
      "[LightGBM] [Info] Number of data points in the train set: 133413, number of used features: 16\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3105\n",
      "[LightGBM] [Info] Start training from score 39.093180\n",
      "[LightGBM] [Info] Number of data points in the train set: 133413, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 39.022521\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3105\n",
      "[LightGBM] [Info] Number of data points in the train set: 133412, number of used features: 16\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3104\n",
      "[LightGBM] [Info] Start training from score 39.069583\n",
      "[LightGBM] [Info] Number of data points in the train set: 133413, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 38.971165\n",
      "[LightGBM] [Info] Start training from score 39.078556\n",
      "Stacking Ensemble training completed!\n"
     ]
    }
   ],
   "source": [
    "base_models = [\n",
    "    ('lgb', lgb.LGBMRegressor(n_estimators=1000, learning_rate=0.05, random_state=42, n_jobs=-1)),\n",
    "    ('xgb', xgb.XGBRegressor(n_estimators=1000, max_depth=7, learning_rate=0.03, random_state=42, n_jobs=-1)),\n",
    "    ('cat', CatBoostRegressor(iterations=1000, learning_rate=0.05, depth=8, random_seed=42, verbose=0))\n",
    "]\n",
    "\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,      \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Stacking Ensemble\")\n",
    "stacking_model.fit(X_train, y_train)\n",
    "print(\"Stacking Ensemble training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a338b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stacking Ensemble Performance ---\n",
      "MAE: 6.6416 | RMSE: 12.9004 | R2 Score: 0.8887\n"
     ]
    }
   ],
   "source": [
    "y_pred = stacking_model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"--- Stacking Ensemble Performance ---\")\n",
    "print(f\"MAE: {mae:.4f} | RMSE: {rmse:.4f} | R2 Score: {r2:.4f}\")\n",
    "\n",
    "# Log to ledger\n",
    "log_path = os.path.join(PATH, 'model_performances.csv')\n",
    "log_data = {\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'model_id': '007',\n",
    "    'model_name': 'Stacking Ensemble (LGBM, XGB, CAT)',\n",
    "    'mae': mae, 'rmse': rmse, 'r2_score': r2,\n",
    "    'features': f'all_numeric_{len(features)}_cols',\n",
    "    'comments': 'Combined top 3 models with Linear Meta-Regressor'\n",
    "}\n",
    "\n",
    "with open(log_path, 'a', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=log_data.keys())\n",
    "    writer.writerow(log_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84acac51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
