{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa3b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a380799",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/Users/beratzengin/Desktop/Github/EcoAir SmartCity Predictor/Data\"\n",
    "STATIONS_CSV = os.path.join(BASE_PATH, \"stations_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af7eca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv(STATIONS_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5764cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Weather for: Maslak\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Github/EcoAir SmartCity Predictor/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3641\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3640\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3642\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:168\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:197\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7668\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7676\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'timestamp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m df = pd.read_csv(yearly_file)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Convert timestamp to datetime for filtering\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtimestamp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Split into 12 months and save individually\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m month \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m13\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Github/EcoAir SmartCity Predictor/.venv/lib/python3.12/site-packages/pandas/core/frame.py:4378\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4378\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4380\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Github/EcoAir SmartCity Predictor/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3648\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3644\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3645\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3646\u001b[39m     ):\n\u001b[32m   3647\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3649\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3650\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3651\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3652\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3653\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'timestamp'"
     ]
    }
   ],
   "source": [
    "for index, row in stations.iterrows():\n",
    "    # Sanitize folder name\n",
    "    station_name = row['Name'].replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "    station_dir = os.path.join(BASE_PATH, station_name)\n",
    "    yearly_file = os.path.join(station_dir, \"weather_2024.csv\")\n",
    "    \n",
    "    if os.path.exists(yearly_file):\n",
    "        print(f\"Processing Weather for: {station_name}\")\n",
    "        \n",
    "        # Read the 8785-row master file\n",
    "        df = pd.read_csv(yearly_file)\n",
    "        \n",
    "        # Convert timestamp to datetime for filtering\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        \n",
    "        # Split into 12 months and save individually\n",
    "        for month in range(1, 13):\n",
    "            month_df = df[df['timestamp'].dt.month == month].copy()\n",
    "            \n",
    "            if not month_df.empty:\n",
    "                month_str = f\"{month:02d}\"\n",
    "                output_path = os.path.join(station_dir, f\"weather_{month_str}.csv\")\n",
    "                month_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        print(f\"12 monthly files created in {station_name}/\")\n",
    "    else:\n",
    "        print(f\"weather_2024.csv NOT FOUND in {station_name}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef6ffa84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Processing: Maslak\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      8\u001b[39m df = pd.read_csv(yearly_file)\n\u001b[32m     10\u001b[39m df.columns = [c.lower() \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m df.columns]\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m time_col = \u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ğŸ” Found time column: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_col\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Convert to datetime\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "for index, row in stations.iterrows():\n",
    "    station_name = row['Name'].replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "    station_dir = os.path.join(BASE_PATH, station_name)\n",
    "    yearly_file = os.path.join(station_dir, \"weather_2024.csv\")\n",
    "    \n",
    "    if os.path.exists(yearly_file):\n",
    "        print(f\"ğŸ“‚ Processing: {station_name}\")\n",
    "        df = pd.read_csv(yearly_file)\n",
    "        \n",
    "        df.columns = [c.lower() for c in df.columns]\n",
    "        \n",
    "        time_col = [c for c in df.columns if 'time' in c][0]\n",
    "        print(f\"  ğŸ” Found time column: '{time_col}'\")\n",
    "        \n",
    "        # Convert to datetime\n",
    "        df[time_col] = pd.to_datetime(df[time_col])\n",
    "        \n",
    "        for month in range(1, 13):\n",
    "            month_df = df[df[time_col].dt.month == month].copy()\n",
    "            if not month_df.empty:\n",
    "                month_str = f\"{month:02d}\"\n",
    "                output_path = os.path.join(station_dir, f\"weather_{month_str}.csv\")\n",
    "                month_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        print(f\"Monthly files created.\")\n",
    "    else:\n",
    "        print(f\"weather_2024.csv NOT FOUND in {station_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "383e1b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                            date  temp   humidity  wind_speed  wind_direction\n",
       "0     2024-01-01 00:00:00+00:00  8.25   85.43088    8.373386       154.53670\n",
       "1     2024-01-01 01:00:00+00:00  8.55   87.24657    6.214563       169.99208\n",
       "2     2024-01-01 02:00:00+00:00  7.95   88.70700    6.638072       167.47120\n",
       "3     2024-01-01 03:00:00+00:00  7.65   88.68145    6.924738       171.02745\n",
       "4     2024-01-01 04:00:00+00:00  7.90   87.78907    6.849467       176.98727\n",
       "...                         ...   ...        ...         ...             ...\n",
       "8779  2024-12-31 19:00:00+00:00  3.90   97.91214    5.269422        82.14678\n",
       "8780  2024-12-31 20:00:00+00:00  3.25  100.00000    4.514377        85.42616\n",
       "8781  2024-12-31 21:00:00+00:00  2.75  100.00000    3.438895        96.00892\n",
       "8782  2024-12-31 22:00:00+00:00  2.45  100.00000    3.284691        99.46225\n",
       "8783  2024-12-31 23:00:00+00:00  1.65  100.00000    1.620000        90.00000\n",
       "\n",
       "[8784 rows x 5 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49acd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Processing: Maslak\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: Esenler\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: Yenibosna\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: BeylikdÃ¼zÃ¼\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: Ãœmraniye_1\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: Aksaray\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: Mobil\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: BeÅŸiktaÅŸ\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: KadÄ±kÃ¶y\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: Sultangazi_1\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: AvcÄ±lar\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: Sultangazi_3\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: ÃœskÃ¼dar_1\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: AlibeykÃ¶y\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: Selimiye\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: D-100_\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: KaÄŸÄ±thane_1\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: Kandilli_1\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: Kartal\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: Ã‡atladÄ±kapÄ±\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: Sultangazi_2\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: BaÄŸcÄ±lar\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: KumkÃ¶y\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: SarÄ±yer\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: BÃ¼yÃ¼kada\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: Sancaktepe\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: ArnavutkÃ¶y\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n",
      "ğŸ“‚ Processing: Tuzla\n",
      "Monthly files (weather_01.csv etc.) created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- PATHS ---\n",
    "BASE_PATH = \"/Users/beratzengin/Desktop/Github/EcoAir SmartCity Predictor/Data\"\n",
    "STATIONS_CSV = os.path.join(BASE_PATH, \"stations_info.csv\")\n",
    "\n",
    "# Load station list\n",
    "stations = pd.read_csv(STATIONS_CSV)\n",
    "\n",
    "for index, row in stations.iterrows():\n",
    "    station_name = row['Name'].replace(\" \", \"_\").replace(\"/\", \"-\")\n",
    "    station_dir = os.path.join(BASE_PATH, station_name)\n",
    "    yearly_file = os.path.join(station_dir, \"weather_2024.csv\")\n",
    "    \n",
    "    if os.path.exists(yearly_file):\n",
    "        print(f\"Processing: {station_name}\")\n",
    "        \n",
    "        # Read the file\n",
    "        df = pd.read_csv(yearly_file)\n",
    "        \n",
    "        # Convert 'date' column to datetime (handling the +00:00 offset)\n",
    "        df['date'] = pd.to_datetime(df['date'], utc=True)\n",
    "        \n",
    "        # Split into 12 months\n",
    "        for month in range(1, 13):\n",
    "            month_df = df[df['date'].dt.month == month].copy()\n",
    "            \n",
    "            if not month_df.empty:\n",
    "                month_str = f\"{month:02d}\"\n",
    "                output_path = os.path.join(station_dir, f\"weather_{month_str}.csv\")\n",
    "                month_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        print(f\"Monthly files (weather_01.csv etc.) created successfully.\")\n",
    "    else:\n",
    "        print(f\"weather_2024.csv NOT FOUND in {station_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e12813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
